{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning LSTM**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_path = \"../data/yahoo_massive_stock_data_2018-2023.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# display the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# display data types of each column\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the count of missing values in each column\n",
    "print(\"is null sum:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the count of duplicate rows\n",
    "print(\"duplicated sum:\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" example csv dataset\n",
    "Date,Open,High,Low,Close,Volume,Dividends,Stock Splits,Company\n",
    "2018-11-29 00:00:00-05:00,43.829760572993,43.8633538041636,42.6395935832266,43.0835075378418,167080000,0,0,AAPL\n",
    "2018-11-29 00:00:00-05:00,104.769074332185,105.519257086357,103.534594914971,104.636131286621,28123200,0,0,MSFT\n",
    "2018-11-29 00:00:00-05:00,54.1764984130859,55.0074996948242,54.0999984741211,54.7290000915527,31004000,0,0,GOOGL\n",
    "2018-11-29 00:00:00-05:00,83.7494964599609,84.4994964599609,82.6165008544922,83.6784973144531,132264000,0,0,AMZN\n",
    "2018-11-29 00:00:00-05:00,39.6927840259795,40.0649038762231,38.7351954599368,39.0378532409668,54917200,0.04,0,NVDA\n",
    "2018-11-29 00:00:00-05:00,135.919998168945,139.990005493164,135.660003662109,138.679992675781,24238700,0,0,META\n",
    "2018-11-29 00:00:00-05:00,23.1333332061768,23.1666679382324,22.6366672515869,22.7446670532227,46210500,0,0,TSLA\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert `Date` column to datetime type as index\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Check for necessary columns\n",
    "required_columns = ['Close']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing columns in dataset: {missing_columns}\")\n",
    "\n",
    "def calculate_simple_and_exponential_moving_average(df, periods):\n",
    "    for period in periods:\n",
    "        # (MA) simple moving average \n",
    "        df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()\n",
    "        # (EMA) exponential moving average\n",
    "        df[f'EMA_{period}'] = df['Close'].ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    \"\"\"\n",
    "    คำนวณ RSI (Relative Strength Index) สำหรับ DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas.Series (ราคาปิด Close)\n",
    "    - window: int (ระยะเวลาในการคำนวณ RSI)\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.Series (RSI)\n",
    "    \"\"\"\n",
    "    delta = data.diff()  # คำนวณการเปลี่ยนแปลงของราคา\n",
    "    gain = (delta.where(delta > 0, 0)).ewm(span=window, adjust=False).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).ewm(span=window, adjust=False).mean()\n",
    "    \n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "        \n",
    "\n",
    "\n",
    "ma_periods = [7, 14, 30, 100]\n",
    "\n",
    "calculate_simple_and_exponential_moving_average(df, ma_periods)\n",
    "df[\"RSI_14\"] = calculate_rsi(df['Close'], window=14)\n",
    "\n",
    "# Fill NaN values with mean of numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "# calculate the relative strength index (RSI)\n",
    "print(\"Preprocessing Completed\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# this modified dataset using `Date` as a index\n",
    "df.to_csv(\"../data/yahoo_massive_stock_data_2018-2023_preprocessed.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" example preprocessed csv dataset\n",
    "\n",
    "Date,Open,High,Low,Close,Volume,Dividends,Stock Splits,Company,MA_7,EMA_7,MA_14,EMA_14,MA_30,EMA_30,MA_100,EMA_100,RSI_14\n",
    "2018-11-29 00:00:00-05:00,43.829760572993,43.8633538041636,42.6395935832266,43.0835075378418,167080000,0.0,0.0,AAPL,140.09596466303415,43.0835075378418,140.09241066496398,43.0835075378418,140.0905064445423,43.0835075378418,140.09118714755536,43.0835075378418,49.865364818081325\n",
    "2018-11-29 00:00:00-05:00,104.769074332185,105.519257086357,103.534594914971,104.636131286621,28123200,0.0,0.0,MSFT,140.09596466303415,58.47166347503659,140.09241066496398,51.29052403767903,140.0905064445423,47.05464455389207,140.09118714755536,44.30237137445129,100.0\n",
    "2018-11-29 00:00:00-05:00,54.1764984130859,55.0074996948242,54.0999984741211,54.7290000915527,31004000,0.0,0.0,GOOGL,140.09596466303415,57.53599762916562,140.09241066496398,51.74898751152885,140.0905064445423,47.54976426599921,140.09118714755536,44.508839269839434,51.66507741377641\n",
    "2018-11-29 00:00:00-05:00,83.7494964599609,84.4994964599609,82.6165008544922,83.6784973144531,132264000,0.0,0.0,AMZN,140.09596466303415,64.07162255048749,140.09241066496398,56.00625548525208,140.0905064445423,49.88065026912527,140.09118714755536,45.28447606280208,63.47973776310287\n",
    "2018-11-29 00:00:00-05:00,39.6927840259795,40.0649038762231,38.7351954599368,39.0378532409668,54917200,0.04,0.0,NVDA,140.09596466303415,57.81318022310732,140.09241066496398,53.74380185268072,140.0905064445423,49.18111497698602,140.09118714755536,45.160780561379596,44.23958268103335\n",
    "2018-11-29 00:00:00-05:00,135.919998168945,139.990005493164,135.660003662109,138.679992675781,24238700,0.0,0.0,META,140.09596466303415,78.02988333627573,140.09241066496398,65.06862729576076,140.0905064445423,54.95523611884376,140.09118714755536,47.01264614780339,68.68464921784869\n",
    "2018-11-29 00:00:00-05:00,23.1333332061768,23.1666679382324,22.6366672515869,22.7446670532227,46210500,0.0,0.0,TSLA,69.51280702863416,64.20857926551247,140.09241066496398,59.42543259675569,140.0905064445423,52.87713488880369,140.09118714755536,46.532092106326544,43.237230884116045\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training model**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "\n",
    "# we uses 7 features ['MA_7', 'EMA_7', 'MA_14', 'EMA_14', 'MA_30', 'EMA_30'] to predict the next day's [`Close`] price as a target\n",
    "features = [\"Close\", \"MA_7\", \"EMA_7\", \"MA_14\", \"EMA_14\", \"MA_30\", \"EMA_30\", \"RSI_14\"]\n",
    "# target = \"Close\"\n",
    "\n",
    "# grouping the dataset by `Company`\n",
    "company_groups = df.groupby(\"Company\")\n",
    "print(\"Number of companies:\", len(company_groups))\n",
    "\n",
    "# Identify numeric columns for scaling\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# apply MinMaxScaler to scale numeric columns only\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# create sequences of time steps\n",
    "def create_dataset(data, time_steps=30):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        x.append(data[i:(i + time_steps)].values)  # ใช้ข้อมูลก่อนหน้า\n",
    "        y.append(data.iloc[i + time_steps]['Close'])  # ใช้ราคาปิดในวันถัดไปเป็นเป้าหมาย\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "def train_lstm_model(company_input_shape) -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, return_sequences=True, input_shape=company_input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))  # output layer ที่ทำนายราคาปิด\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "# create each company's model\n",
    "company_model = {}\n",
    "for company, group in company_groups:\n",
    "    company_data = group[features]\n",
    "    \n",
    "    # create sequences of time steps\n",
    "    time_steps = 30     # number of time steps previour days to predict the next day's `Close`` price\n",
    "    x, y = create_dataset(company_data, time_steps)\n",
    "    \n",
    "    company_model[company] = (x, y)\n",
    "    \n",
    "    \n",
    "count = 0\n",
    "for company, (x_train, y_train) in company_model.items():\n",
    "    count += 1\n",
    "    print(f\"\\n#{count} Training model for {company}\")\n",
    "    model = train_lstm_model(company_input_shape=(x_train.shape[1], x_train.shape[2]))\n",
    "    \n",
    "    # training the model\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "    \n",
    "    # save the model\n",
    "    model.save(f\"../models/lumina_{company}.h5\")\n",
    "    \n",
    "\n",
    "print(\"Training Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

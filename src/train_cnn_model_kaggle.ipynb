{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# This code based-on Kaggle editor\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset:**\n",
    "- https://www.kaggle.com/datasets/a2015003713/militaryaircraftdetectiondataset\n",
    "\n",
    "**Reference:**\n",
    "1. https://keras.io/api/applications/\n",
    "2. https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "3. https://www.tensorflow.org/tutorials/keras/classification\n",
    "4. https://github.com/AvinashNath2/Image-Classification-using-Keras/tree/master\n",
    "\n",
    "`<3` **AvinashNath2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used to build a simple ConvNet model for multi-class image classification.\n",
    "based on the dataset of military aircraft detection.\n",
    "using P100 GPU on Kaggle.\n",
    "\"\"\"\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Define dataset directory\n",
    "data_dir = '/kaggle/input/militaryaircraftdetectiondataset/crop'\n",
    "\n",
    "# Preprocessing: used to rescale the pixel values from [0, 255] to [0, 1]\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)  # 40% for validation\n",
    "batch_size = 32\n",
    "\n",
    "# Automatically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',  # Assuming more than 2 classes\n",
    "        subset='training')  # Use 70% for training\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',  # Assuming more than 2 classes\n",
    "        subset='validation')  # Use 30% for validation\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "class_weights_dict\n",
    "\n",
    "# Build a simple ConvNet model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')  # Adjust for number of classes\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',  # For multi-class classification\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs = 50\n",
    "train_samples = train_generator.samples\n",
    "validation_samples = validation_generator.samples\n",
    "\n",
    "result = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "\n",
    "test_accuracy_string = str(test_accuracy).replace('.','')[:5]\n",
    "\n",
    "model.save(f\"afdet_{test_accuracy_string}.h5\")\n",
    "print(\"test_accuracy\", test_accuracy_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph from result.history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Accuracy and Loss\n",
    "def plot_training_history(history):\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the training history\n",
    "plot_training_history(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reset the validation generator to ensure predictions start from the first batch\n",
    "validation_generator.reset()\n",
    "\n",
    "# Predict for the entire validation set\n",
    "y_pred = model.predict(validation_generator, steps=len(validation_generator), verbose=1)\n",
    "\n",
    "# Get true labels and predicted labels\n",
    "y_true = validation_generator.classes  # True labels from the validation generator\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with highest probability\n",
    "\n",
    "# Mapping class indices to class names\n",
    "g_dict = validation_generator.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap='Blues'):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "plot_confusion_matrix(cm, classes, title='Confusion Matrix')\n",
    "\n",
    "# Generate and print Classification Report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_true, y_pred_classes, target_names=classes))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
